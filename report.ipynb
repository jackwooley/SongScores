{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song-Scores\n",
    "\n",
    "This is a project I've been working on for a while. Initially, I had wanted to come up with my own metric for tracking popularity using my own custom formulas - that was the genesis for this project, back in January or February of this year. I thought it would be cool to look at things like the ratio of plays on a song vs. an artist's total monthly listeners to try to capture things like if you were listening to deep cuts from a well-known artist (think Alter Ego by Tame Impala), or if you were listening to big hits by lesser-known artists (something along the lines of Replay by Iyaz). One question that raised, though, was how to determine indieness. Is a popular song from an unpopular artist more indie than an unpopular song from a popular artist? I wanted to calculate something that would allow me to answer that question quantitatively, not qualitatively. (As a quick aside - I like analyzing music with quantitatively rigorous methodology, but I don't think that's how you should *listen* to it. I think your music choice is an expression of your personality, interests, tastes, and preferences, and should reflect that.)\n",
    "\n",
    "Originally, I wrote this all in one big `.py` file, but it didn't lend itself nicely to presentation. This notebook provides a more interactive look at how it analyzes playlists.\n",
    "\n",
    "First, all the packages are imported and some boring but important stuff (authentication) is set up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import config  # used for auth stuff\n",
    "import re\n",
    "BASE_URL = 'https://api.spotify.com/v1/'\n",
    "AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "\n",
    "# get authentication headers and stuff back (boring)\n",
    "def auth_stuff(client_id: str, client_secret: str):\n",
    "    \n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token_ = auth_response_data['access_token']\n",
    "\n",
    "    headers_ = {\n",
    "        'Authorization': f'Bearer {access_token_}'\n",
    "    }\n",
    "\n",
    "    return access_token_, headers_  # does this need the access_token_ to be returned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the playlist processing starts. The first step is to pull the playlist data from the Spotify API. To do that, you need the playlist id, which corresponds to the last segment of the URL when you open a spotify playlist link in a browser, like the section bolded below:\n",
    "<pre>\n",
    "https://open.spotify.com/playlist/<span style=\"font-weight: bold;\">2wIJNW0Zn7LK6mi2slwdAF</span>\n",
    "</pre>\n",
    "\n",
    "That segment of the URL is a unique identifier for each playlist, and with it, you can pull back a large amount of metadata. For this analysis, I'll be working with a playlist called \"4 aspen pt. 4\". This is one I've been working on for my little sister while she's been away on a mission trip for our church, and the fourth in a series of playlists I have made for her over the past couple years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull playlist info back from api\n",
    "# get track, artist, album ids from the playlist id\n",
    "def playlist_processor(playlist_id: str, headers_: dict):\n",
    "    playlist_info = requests.get(f'{BASE_URL}playlists/{playlist_id}/tracks', headers=headers_)\n",
    "\n",
    "    # playlist info will be what's returned from the api call in get_all_playlist_ids\n",
    "    try:\n",
    "        songs = playlist_info.json()['items']\n",
    "    except KeyError as ke:\n",
    "        print(f'\\nOh no! This message indicates an error ({ke=}) occurred. Make sure the playlist you\\'re attempting to analyze is not private.')\n",
    "        songs = []\n",
    "\n",
    "    song_ids = []\n",
    "    album_ids = []\n",
    "    artist_ids = []\n",
    "\n",
    "    try:\n",
    "        for i in range(0, len(songs)):\n",
    "            song_ids.append(songs[i]['track']['id'])  # add all the song ids to a list\n",
    "            album_ids.append(songs[i]['track']['album']['id'])  # add all the album ids to a list\n",
    "            artists = songs[i]['track']['artists']  # add all the artist ids to a list\n",
    "            artist_id_subsets = []  # leave this here for when u go back to fix the artist api calls\n",
    "\n",
    "            for j in range(0, len(artists)):\n",
    "                artist_id_subsets.append(artists[j]['id'])\n",
    "            \n",
    "            artist_ids.append(artist_id_subsets)\n",
    "    \n",
    "    except TypeError as te:\n",
    "        print(f'iteration {i} caused a problem: {te=}. Does this playlist contain songs?')\n",
    "        if len(song_ids) == i-1:\n",
    "            song_ids[i] = None\n",
    "        if len(album_ids) == i-1:\n",
    "            album_ids[i] = None\n",
    "        if len(artist_ids) == i-1:\n",
    "            artist_ids[i] = None\n",
    "\n",
    "    return song_ids, album_ids, artist_ids\n",
    "\n",
    "\n",
    "# The API only allows you to get info on 50 records at a time. This function groups your list of ids to query information about into lists of 50 ids, nested within each list.\n",
    "# you can change the 'members' paramter to be less than 50 if you want (i.e., if the api changes or something maybe>)\n",
    "def nest_id_lists(id_list: list, members: int):\n",
    "    if len(id_list) > members:  # if the list is longer than `members` items, figure out how many API calls to make\n",
    "        if len(id_list) % members != 0:\n",
    "            how_many_times = (len(id_list) / members) + 1\n",
    "        else:\n",
    "            how_many_times = len(id_list) / members\n",
    "        \n",
    "        start = 0\n",
    "        end = members\n",
    "\n",
    "        nested_list = []\n",
    "\n",
    "        for i in range(0, int(how_many_times)):\n",
    "            nested_list.append(list(id_list)[start:end])\n",
    "            start += members  # increment to get the next values starting at previous end\n",
    "            if end + members > len(id_list):\n",
    "                end = len(id_list)\n",
    "            else:\n",
    "                end += members\n",
    "        \n",
    "        song_ids_ = nested_list\n",
    "\n",
    "    else:\n",
    "        song_ids_ = []\n",
    "        song_ids_.append(id_list)\n",
    "\n",
    "    return song_ids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting the project, I found that a lot of the data I wanted, like number of plays on a track and total monthly listeners for an artist, were not readily available via the API, so the initial goals shifted slightly, and I had to come up with different formulas to calculate indieness. While it didn't have everything I originally had in mind, one cool feature of Spotify's API is that you can pull back some internal metrics that they use, including one to quantify \"popularity\". It's scaled from 0-100, and indicates how popular a certain track or album is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get popularity metrics for songs and albums\n",
    "def get_popularities(id_list: list, headers_: dict, endpoint: str, batch_size: int):\n",
    "    #  endpoint should be either 'tracks' or 'albums'\n",
    "    try:\n",
    "        ids_new = nest_id_lists(id_list, batch_size)\n",
    "        popularity_list = []\n",
    "\n",
    "        for list_ in ids_new:\n",
    "            subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "            popularities_raw = requests.get(f'{BASE_URL}{endpoint}/?ids={subset_of_ids}', headers=headers_)\n",
    "            \n",
    "            for j in range(0, len(list_)):\n",
    "                popularity_list.append(popularities_raw.json()[endpoint][j]['popularity'])\n",
    "    \n",
    "    except KeyError as k:\n",
    "        print(f'{k=}. Did you use the wrong endpoint?')\n",
    "\n",
    "    return popularity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had the main playlist analyzer working, I let the project rest for a while - most of this has been done since August, and was initially all I set out to do. However, the other day, I decided I wanted to try expanding the analysis. After reading through some of the Spotify API docs, I decided to work with the \"Audio Analysis\" endpoint to get more data back. It offers mostly quantitative variables that are used to express everything from how acoustic a song sounds to whether it's in a major or minor key. I used `sklearn`'s `MinMaxScaler()` to normalize each feature. I initially thought to use `StandardScaler()`, but since each column's mean ends up being zero, it caused weird results when performing some of the calculations described in the next markdown cell, so I switched my approach to use min-max scaling instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_features(id_list: list, headers_: dict, endpoint: str, batch_size: int):\n",
    "    #  endpoint should be either 'tracks' or 'albums'\n",
    "    try:\n",
    "        ids_new = nest_id_lists(id_list, batch_size)\n",
    "        dfs_to_concat = []\n",
    "\n",
    "        for list_ in ids_new:\n",
    "            subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "            features_raw = requests.get(f'{BASE_URL}{endpoint}/?ids={subset_of_ids}', headers=headers_)\n",
    "            music_data = pd.json_normalize(features_raw.json()['audio_features'])\n",
    "            music_data.drop(['type', 'id', 'uri', 'analysis_url', 'time_signature'], axis=1, inplace=True)\n",
    "            dfs_to_concat.append(music_data)\n",
    "            # useful_music_features\n",
    "\n",
    "        useful_music_features = pd.concat(dfs_to_concat)\n",
    "    \n",
    "    except KeyError as k:\n",
    "        print(f'{k=}. Did you use the wrong endpoint?')\n",
    "\n",
    "    return useful_music_features\n",
    "\n",
    "\n",
    "def preprocess_the_data(df: pd.DataFrame):\n",
    "    track_ids = df['track_href']\n",
    "    del df['track_href']\n",
    "\n",
    "    mms = MinMaxScaler()\n",
    "    scaled = mms.fit_transform(df)\n",
    "    data_array = np.array(scaled)\n",
    "    \n",
    "    return data_array, track_ids\n",
    "\n",
    "\n",
    "def get_mean_song(df: np.array, ids: pd.Series, headers_):\n",
    "    \n",
    "    ids = np.array(ids).reshape(1, -1)\n",
    "    mean_ = np.mean(df, axis=0)\n",
    "    min_distance = 1000000  # arbitrary really big distance that all other distances will be less than\n",
    "    for i in range(0, df.shape[0]):\n",
    "        distance = euclidean_distances(np.array(df[i,:]).reshape(1, -1), np.array(mean_).reshape(1, -1))\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            mean_song = ids[0][i]\n",
    "\n",
    "    ms = requests.get(mean_song, headers=headers_)\n",
    "    track_name = ms.json()['name']\n",
    "    artist = ms.json()['album']['artists'][0]['name']  ### TODO -- update this to support multiple artists\n",
    "\n",
    "    track_message = f'The song that best represents this playlist is {track_name} by {artist}.'\n",
    "\n",
    "    return track_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is returned and normalized, there are about 30 features to work with. I decided to find out what the \"average\" song was for a given playlist based on these metrics. To do that, I treated each row as a vector. To figure out the mean values for all the songs in the playlist, I take a column-wise average of the data matrix and use that vector as the \"average\" song, and then compute the a similarity metric between each song in the playlist and the \"average song\" vector. The song with the highest similarity score is then returned as the \"average\" song in the playlist, or the single song on the playlist that best represents the playlist.\n",
    "\n",
    "The similarity metric I decided to use was the Euclidean distance. Initially, I was using cosine similarity, but I wanted to take the magnitude of the vectors into acccount more than the angle between them. Euclidean distance is a metric that returns the distance between the tips of two vectors; intuitively, you can think about it as showing the distance between any two points in space. In the context of this project, what this is calculating is the distance between the \"average\" song vector and a vector representing a given song from the playlist. Based on this interpretation, the song in the playlist closest to the \"average\", or most representative of the playlist, is then the song vector whose tip is \"closest\" to the \"average song\" vector's tip. While it has the disadvantage of not explicitly returning information about the angle between the two vectors, if two vectors have a relatively low Euclidean distance, they will likely be pointing in a fairly similar direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_popularities(id_list: list, headers_: dict):\n",
    "    \n",
    "    popularity_list = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    raw_popularities = get_popularities(starred, headers_, 'artists', 20)  # artists api is rate-limited to 20 instead of 50\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        popularity_list.append(raw_popularities[start:end])\n",
    "        start = end\n",
    "\n",
    "    for i in range(0, len(popularity_list)):\n",
    "        if len(popularity_list[i]) != len(id_list[i]):\n",
    "            print('bro')\n",
    "\n",
    "    return popularity_list\n",
    "\n",
    "\n",
    "def get_artist_follower_count(id_list: list, headers_: dict, batch_size: int):  # TODO -- NOT TESTED YET\n",
    "    # almost identical to the get popularity one, but it returns # of an artist's followers as opposed to popularity\n",
    "\n",
    "    clean_followers_list = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    ids_new = nest_id_lists(starred, batch_size)\n",
    "\n",
    "    followers_list = []\n",
    "\n",
    "    for list_ in ids_new:\n",
    "        subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "        followers_raw = requests.get(f'{BASE_URL}artists/?ids={subset_of_ids}', headers=headers_)\n",
    "        for j in range(0, len(list_)):\n",
    "            followers_list.append(followers_raw.json()['artists'][j]['followers']['total'])\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        clean_followers_list.append(followers_list[start:end])\n",
    "        start = end\n",
    "\n",
    "    return clean_followers_list\n",
    "\n",
    "\n",
    "def get_artists_top_songs(id_list: list, headers_: dict, batch_size: int):\n",
    "    clean_top_songs = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    top_songs = []\n",
    "\n",
    "    for artist in starred:\n",
    "        top_songs_raw = requests.get(f'https://api.spotify.com/v1/artists/{artist}/top-tracks?market=US', headers=headers_)  #requests.get(f'{BASE_URL}artists/{starred[0]}/top-tracks', headers=headers_)\n",
    "        for j in range(0, len(top_songs_raw.json()['tracks'])):\n",
    "            top_songs.append(top_songs_raw.json()['tracks'][j]['album']['id'])\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        clean_top_songs.append(top_songs[start:end])\n",
    "        start = end\n",
    "\n",
    "    return clean_top_songs\n",
    "\n",
    "\n",
    "def get_playlist_name(playlist_id: str, headers_: dict):\n",
    "\n",
    "    playlist_name_raw = requests.get(f'{BASE_URL}playlists/{playlist_id}', headers=headers_)\n",
    "    try:\n",
    "        playlist_name_clean = playlist_name_raw.json()['name']\n",
    "    except KeyError as ke:\n",
    "        print('\\nThere seems to be a problem retrieving the playlist name. Double-check to make sure the playlist ID is correct, and that it is not set to private.')\n",
    "        playlist_name_clean = RuntimeWarning\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    return playlist_name_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the preprocessing functions are up and running, it's time to tie it all together in the `main()` function. This bundles everything else in the script together, pulling data about artists, songs, and playlists, and summarizes it all in a concise message about the \"indieness\" rating and the most representative song. \n",
    "\n",
    "To examine the function that computes indieness, look at the section near the comment that says \"formula for rating songs\":\n",
    "\n",
    "It works by computing this metric for each song in a playlist. First, it calculates $100-popularity$. This means that *more* popular songs are given less weight when a higher score indicates more indieness. Next, it calculates the $100-mean(artist\\_popularity)$. It was necessary to average out artist popularity to account for songs where there were more than one artist credited with working on it. This way, if one artist was really popular and the other really unpopular, it would help balance out that discrepancy. Most of the time though, it's just taking the average of 1 number and returning the original number. After that, it calculates $100-album\\_popularity)$, following the same logic as the previous two metrics. Once that's done, it gets a little more complicated, and calculates $$90 - (mean(artist\\_followers[j]) / 1000000)) \\times 1.11111111$$\n",
    "To explain, from the inside out: first, it takes the mean of the artist or artists' follower counts. Then, it divides by a million, to make the number easier to work with. Since we want artists with a *higher* number of followers to get *fewer* \"points\" here, we subtract that average follower value from $90$. $90,000,000$ is right about the maximum number of followers any artist on Spotify currently has, with Taylor Swift setting the bar. The $\\times 1.111...$ at the end serves to scale this up to the same scale as the rest of the individual popularity metrics ($90$, which is the maximum observed value of popularity times $1.111...$ then becomes approximately $100$). From there, the total sum of all 4 variables comes out to be somewhere on the interval $[0, 400]$, which is then divided by $4$ and returned as an easily interpretable rating on the interval $[1, 100]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the playlist 4 aspen pt. 4, this is your indieness score:\n",
      "50.107\n",
      "It is scaled from 0-100, with 100 being the most indie and 0 being the least indie.\n",
      "\n",
      "The song that best represents this playlist is Cherry Flavoured by The Neighbourhood.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def main(playlist_ids: str, client_id: str, client_secret: str):\n",
    "    access_token, headers = auth_stuff(client_id, client_secret)\n",
    "\n",
    "    # playlists = get_all_playlist_ids(user_id, headers)\n",
    "    \n",
    "    # split the string into a list if necessary\n",
    "    playlist_id_list = re.sub('\\s*', '', playlist_ids).split(',')\n",
    "\n",
    "    song_ids_all, album_ids_all, artist_ids_all = [], [], []\n",
    "    \n",
    "    for i in range(0, len(playlist_id_list)):\n",
    "        song_ids, album_ids, artist_ids = playlist_processor(playlist_id_list[i], headers)\n",
    "        if len(song_ids) > 0:\n",
    "            song_ids_all.append(song_ids)\n",
    "            album_ids_all.append(album_ids)\n",
    "            artist_ids_all.append(artist_ids)\n",
    "\n",
    "        medians = []\n",
    "\n",
    "        for k in range(0, len(song_ids_all)):\n",
    "            song_popularities = get_popularities(song_ids_all[k], headers, 'tracks', 50)\n",
    "            \n",
    "            more_features = get_more_features(song_ids_all[k], headers, 'audio-features', 50)\n",
    "\n",
    "            scaled_features, ids = preprocess_the_data(more_features)\n",
    "\n",
    "            track_message = get_mean_song(scaled_features, ids, headers)\n",
    "\n",
    "            artist_popularities = get_artist_popularities(artist_ids_all[k], headers)\n",
    "\n",
    "            artist_followers = get_artist_follower_count(artist_ids_all[k], headers, 50)\n",
    "\n",
    "            album_popularities = get_popularities(album_ids_all[k], headers, 'albums', 20)\n",
    "\n",
    "            all_raw_metrics = []\n",
    "\n",
    "            # formula for rating songs\n",
    "            for j in range(0, len(song_popularities)):\n",
    "                jth_song_metric = sum(\n",
    "                    [(100 - song_popularities[j]),  # \n",
    "                    (100 - np.mean(artist_popularities[j])),\n",
    "                    (100 - np.mean(album_popularities[j])),\n",
    "                    ((90 - (np.mean(artist_followers[j]) / 1000000)) * 1.11111111)]  # last i checked, taylor swift had the most followers, with roughly 90 million\n",
    "                                                                                     # this allows her to be the top end of the spectrum, and then multiplying by 1.111111 adjusts it so the scale is roughly 0-100\n",
    "                ) / 4\n",
    "                # append all metric scores to a list for each playlist\n",
    "                all_raw_metrics.append(jth_song_metric)\n",
    "            \n",
    "            medians.append(np.median(all_raw_metrics)) # get the median score for a given playlist\n",
    "\n",
    "        playlist_name = get_playlist_name(playlist_id_list[i], headers)\n",
    "        if type(playlist_name) != str:\n",
    "            print(f'\\nYour playlist score could not be calculated. Be sure the playlist is public before trying again.')\n",
    "        else:\n",
    "            print(f'For the playlist {playlist_name}, this is your indieness score:\\n{round(np.mean(medians), 3)}\\nIt is scaled from 0-100, with 100 being the most indie and 0 being the least indie.')\n",
    "            print(f'\\n{track_message}')\n",
    "\n",
    "    return # np.mean(medians)\n",
    "\n",
    "main('2wIJNW0Zn7LK6mi2slwdAF', config.id_, config.secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the cell above displays a message describing the results of the analysis of the playlist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
