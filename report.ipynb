{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, I wrote this all in one big `.py` file, but it didn't lend itself nicely to presentation. This notebook provides a look at how playlists are analyzed. \n",
    "\n",
    "First, all the packages are imported and some boring but important stuff (authentication) is set up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import config  # used for auth stuff\n",
    "import re\n",
    "BASE_URL = 'https://api.spotify.com/v1/'\n",
    "AUTH_URL = 'https://accounts.spotify.com/api/token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get authentication headers and stuff back (boring)\n",
    "def auth_stuff(client_id: str, client_secret: str):\n",
    "    \n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token_ = auth_response_data['access_token']\n",
    "\n",
    "    headers_ = {\n",
    "        'Authorization': f'Bearer {access_token_}'\n",
    "    }\n",
    "\n",
    "    return access_token_, headers_  # does this need the access_token_ to be returned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the playlist processing starts. The first step is to pull the playlist data from the Spotify API. To do that, you need the playlist id, which corresponds to the last segment of the URL when you open a spotify playlist link in a browser, like the section bolded below:\n",
    "<pre>\n",
    "https://open.spotify.com/playlist/<span style=\"font-weight: bold;\">2wIJNW0Zn7LK6mi2slwdAF</span>\n",
    "</pre>\n",
    "\n",
    "That segment of the URL is a unique identifier for each playlist, and with it, you can pull back a large amount of metadata. For this analysis, I'll be working with a playlist called \"4 aspen pt. 4\". This is one I've been working on for my little sister while she's been away on a mission trip for our church, and the fourth in a series of playlists I have made for her over the past couple years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull playlist info back from api\n",
    "# get track, artist, album ids from the playlist id\n",
    "def playlist_processor(playlist_id: str, headers_: dict):\n",
    "    playlist_info = requests.get(f'{BASE_URL}playlists/{playlist_id}/tracks', headers=headers_)\n",
    "\n",
    "    # playlist info will be what's returned from the api call in get_all_playlist_ids\n",
    "    try:\n",
    "        songs = playlist_info.json()['items']\n",
    "    except KeyError as ke:\n",
    "        print(f'\\nOh no! This message indicates an error ({ke=}) occurred. Make sure the playlist you\\'re attempting to analyze is not private.')\n",
    "        songs = []\n",
    "\n",
    "    song_ids = []\n",
    "    album_ids = []\n",
    "    artist_ids = []\n",
    "\n",
    "    try:\n",
    "        for i in range(0, len(songs)):\n",
    "            song_ids.append(songs[i]['track']['id'])  # add all the song ids to a list\n",
    "            album_ids.append(songs[i]['track']['album']['id'])  # add all the album ids to a list\n",
    "            artists = songs[i]['track']['artists']  # add all the artist ids to a list\n",
    "            artist_id_subsets = []  # leave this here for when u go back to fix the artist api calls\n",
    "\n",
    "            for j in range(0, len(artists)):\n",
    "                artist_id_subsets.append(artists[j]['id'])\n",
    "            \n",
    "            artist_ids.append(artist_id_subsets)\n",
    "    \n",
    "    except TypeError as te:\n",
    "        print(f'iteration {i} caused a problem: {te=}. Does this playlist contain songs?')\n",
    "        if len(song_ids) == i-1:\n",
    "            song_ids[i] = None\n",
    "        if len(album_ids) == i-1:\n",
    "            album_ids[i] = None\n",
    "        if len(artist_ids) == i-1:\n",
    "            artist_ids[i] = None\n",
    "\n",
    "    return song_ids, album_ids, artist_ids\n",
    "\n",
    "\n",
    "# The API only allows you to get info on 50 records at a time. This function groups your list of ids to query information about into lists of 50 ids, nested within each list.\n",
    "# you can change the 'members' paramter to be less than 50 if you want (i.e., if the api changes or something maybe>)\n",
    "def nest_id_lists(id_list: list, members: int):\n",
    "    if len(id_list) > members:  # if the list is longer than `members` items, figure out how many API calls to make\n",
    "        if len(id_list) % members != 0:\n",
    "            how_many_times = (len(id_list) / members) + 1\n",
    "        else:\n",
    "            how_many_times = len(id_list) / members\n",
    "        \n",
    "        start = 0\n",
    "        end = members\n",
    "\n",
    "        nested_list = []\n",
    "\n",
    "        for i in range(0, int(how_many_times)):\n",
    "            nested_list.append(list(id_list)[start:end])\n",
    "            start += members  # increment to get the next values starting at previous end\n",
    "            if end + members > len(id_list):\n",
    "                end = len(id_list)\n",
    "            else:\n",
    "                end += members\n",
    "        \n",
    "        song_ids_ = nested_list\n",
    "\n",
    "    else:\n",
    "        song_ids_ = []\n",
    "        song_ids_.append(id_list)\n",
    "\n",
    "    return song_ids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cool feature of Spotify's API is that you can pull back some internal metrics that they use, including one to quantify \"popularity\". It's scaled from 0-100, and indicates how popular a certain track or album is. \n",
    "\n",
    "Initially, I had wanted to come up with my own metric for tracking popularity using a formula like the following - that was the genesis for this project:\n",
    "### TODO -- ADD ONE OF THE FORMULAS IN HERE\n",
    "$$\n",
    "track\\_popularity = \\frac{1}{log(num\\_of\\_song\\_plays)} \\times \\frac{1}{log(artists\\_monthly\\_listeners)}\n",
    "$$\n",
    "However, some of the datapoints I wanted, like plays on a track and total monthly listeners for an artist were not available via the API, so I made do with the precomputed \"popularity\" feature. \n",
    "\n",
    "I made do with Spotify's \"popularity\" metric, and it worked well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get popularity metrics for songs and albums\n",
    "def get_popularities(id_list: list, headers_: dict, endpoint: str, batch_size: int):\n",
    "    #  endpoint should be either 'tracks' or 'albums'\n",
    "    try:\n",
    "        ids_new = nest_id_lists(id_list, batch_size)\n",
    "        popularity_list = []\n",
    "\n",
    "        for list_ in ids_new:\n",
    "            subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "            popularities_raw = requests.get(f'{BASE_URL}{endpoint}/?ids={subset_of_ids}', headers=headers_)\n",
    "            \n",
    "            for j in range(0, len(list_)):\n",
    "                popularity_list.append(popularities_raw.json()[endpoint][j]['popularity'])\n",
    "    \n",
    "    except KeyError as k:\n",
    "        print(f'{k=}. Did you use the wrong endpoint?')\n",
    "\n",
    "    return popularity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had that working, I let the project rest for a while - that part has been done since August, and was initially all I set out to do. However, the other day, I decided I wanted to try expanding the analysis. After reading through some of the Spotify API docs, I decided to work with the \"Audio Analysis\" endpoint to get more data back. It offers mostly quantitative variables that are used to express everything from how acoustic a song sounds to whether it's in a major or minor key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_features(id_list: list, headers_: dict, endpoint: str, batch_size: int):\n",
    "    #  endpoint should be either 'tracks' or 'albums'\n",
    "    try:\n",
    "        ids_new = nest_id_lists(id_list, batch_size)\n",
    "        dfs_to_concat = []\n",
    "\n",
    "        for list_ in ids_new:\n",
    "            subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "            features_raw = requests.get(f'{BASE_URL}{endpoint}/?ids={subset_of_ids}', headers=headers_)\n",
    "            music_data = pd.json_normalize(features_raw.json()['audio_features'])\n",
    "            music_data.drop(['type', 'id', 'uri', 'analysis_url', 'time_signature'], axis=1, inplace=True)\n",
    "            dfs_to_concat.append(music_data)\n",
    "            # useful_music_features\n",
    "\n",
    "        useful_music_features = pd.concat(dfs_to_concat)\n",
    "    \n",
    "    except KeyError as k:\n",
    "        print(f'{k=}. Did you use the wrong endpoint?')\n",
    "\n",
    "    return useful_music_features\n",
    "\n",
    "\n",
    "def preprocess_the_data(df: pd.DataFrame):\n",
    "    track_ids = df['track_href']\n",
    "    del df['track_href']\n",
    "    data_array = np.array(df)\n",
    "\n",
    "    return data_array, track_ids\n",
    "\n",
    "\n",
    "def get_mean_song(df: np.array, ids: pd.Series, headers_):\n",
    "    \n",
    "    ids = np.array(ids).reshape(1, -1)\n",
    "    mean_ = np.mean(df, axis=0)\n",
    "    min_distance = 1000000  # an arbitrary value that should not ever be exceeded based on the range of the values that the variables can take (+/-10)\n",
    "    for i in range(0, df.shape[0]):\n",
    "        distance = euclidean_distances(np.array(df[i,:]).reshape(1, -1), np.array(mean_).reshape(1, -1))\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            mean_song = ids[0][i]\n",
    "\n",
    "    ms = requests.get(mean_song, headers=headers_)\n",
    "    track_name = ms.json()['name']\n",
    "    artist = ms.json()['album']['artists'][0]['name']  ### TODO -- update this to support multiple artists\n",
    "\n",
    "    track_message = f'The song that best represents this playlist is {track_name} by {artist}.'\n",
    "\n",
    "    return track_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is returned, there are about 30 features to work with. I decided to find out what the \"average\" song was for a given playlist based on these metrics. To do that, I treated each row as a vector. To figure out the mean values for all the songs in the playlist, I take a column-wise average and return that as the \"average\" song, and then compute the a similarity metric between each song in the playlist and the \"average song\" vector. The song with the highest similarity score is then returned as the \"average\" song in the playlist, or the single song on the playlist that best represents the playlist.\n",
    "\n",
    "The similarity metric I decided to use was the Euclidean distance. Initially, I was using cosine similarity, but I wanted to take the magnitude of the vectors into acccount too. Euclidean distance is a metric that returns the distance between the tips of two vectors; intuitively, you can think about it as showing the distance between any two points in space. In the context of this project, what this is calculating is the distance between the \"average\" song and a given song from the playlist. Based on this interpretation, the \"average\" song is then the song vector whose tip is \"closest\" to the \"average song\" vector's tip. While it has the disadvantage of not explicitly returning information about the angle between the two vectors, if two vectors have a low euclidean distance, they will likely be pointing in a similar direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_popularities(id_list: list, headers_: dict):\n",
    "    \n",
    "    popularity_list = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    raw_popularities = get_popularities(starred, headers_, 'artists', 20)  # artists api is rate-limited to 20 instead of 50\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        popularity_list.append(raw_popularities[start:end])\n",
    "        start = end\n",
    "\n",
    "    for i in range(0, len(popularity_list)):\n",
    "        if len(popularity_list[i]) != len(id_list[i]):\n",
    "            print('bro')\n",
    "\n",
    "    return popularity_list\n",
    "\n",
    "\n",
    "def get_artist_follower_count(id_list: list, headers_: dict, batch_size: int):  # TODO -- NOT TESTED YET\n",
    "    # almost identical to the get popularity one, but it returns # of an artist's followers as opposed to popularity\n",
    "\n",
    "    clean_followers_list = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    ids_new = nest_id_lists(starred, batch_size)\n",
    "\n",
    "    followers_list = []\n",
    "\n",
    "    for list_ in ids_new:\n",
    "        subset_of_ids = str(list_).strip('[\\'').strip('\\']').replace('\\', \\'', ',')#.replace('\\'], [\\'', '\\',\\'')\n",
    "        followers_raw = requests.get(f'{BASE_URL}artists/?ids={subset_of_ids}', headers=headers_)\n",
    "        for j in range(0, len(list_)):\n",
    "            followers_list.append(followers_raw.json()['artists'][j]['followers']['total'])\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        clean_followers_list.append(followers_list[start:end])\n",
    "        start = end\n",
    "\n",
    "    return clean_followers_list\n",
    "\n",
    "\n",
    "def get_artists_top_songs(id_list: list, headers_: dict, batch_size: int):\n",
    "    clean_top_songs = []\n",
    "    lengths = []\n",
    "    starred = []\n",
    "\n",
    "    for i in id_list:\n",
    "        lengths.append(len(i))\n",
    "        starred = [*starred, *i]\n",
    "\n",
    "    top_songs = []\n",
    "\n",
    "    for artist in starred:\n",
    "        top_songs_raw = requests.get(f'https://api.spotify.com/v1/artists/{artist}/top-tracks?market=US', headers=headers_)  #requests.get(f'{BASE_URL}artists/{starred[0]}/top-tracks', headers=headers_)\n",
    "        for j in range(0, len(top_songs_raw.json()['tracks'])):\n",
    "            top_songs.append(top_songs_raw.json()['tracks'][j]['album']['id'])\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in lengths:\n",
    "        end += i\n",
    "        clean_top_songs.append(top_songs[start:end])\n",
    "        start = end\n",
    "\n",
    "    return clean_top_songs\n",
    "\n",
    "\n",
    "def get_playlist_name(playlist_id: str, headers_: dict):\n",
    "\n",
    "    playlist_name_raw = requests.get(f'{BASE_URL}playlists/{playlist_id}', headers=headers_)\n",
    "    try:\n",
    "        playlist_name_clean = playlist_name_raw.json()['name']\n",
    "    except KeyError as ke:\n",
    "        print('\\nThere seems to be a problem retrieving the playlist name. Double-check to make sure the playlist ID is correct, and that it is not set to private.')\n",
    "        playlist_name_clean = RuntimeWarning\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    return playlist_name_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the preprocessing functions are up and running, it's time to tie it all together in the `main()` function. This bundles everything else in the script together, pulling data about artists, songs, and playlists, and summarizes it all in a concise message about the \"indieness\" rating and the most representative song. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the playlist 4 aspen pt. 4, this is your indieness score:\n",
      "49.220773593749996\n",
      "It is scaled from 0-100, with 100 being the most indie and 0 being the least indie.\n",
      "\n",
      "The song that best represents this playlist is Past Life by Tame Impala.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.220773593749996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "def main(playlist_ids: str, client_id: str, client_secret: str):\n",
    "    access_token, headers = auth_stuff(client_id, client_secret)\n",
    "\n",
    "    # playlists = get_all_playlist_ids(user_id, headers)\n",
    "    \n",
    "    # split the string into a list if necessary\n",
    "    playlist_id_list = re.sub('\\s*', '', playlist_ids).split(',')\n",
    "\n",
    "    song_ids_all, album_ids_all, artist_ids_all = [], [], []\n",
    "    \n",
    "    for i in range(0, len(playlist_id_list)):\n",
    "        song_ids, album_ids, artist_ids = playlist_processor(playlist_id_list[i], headers)\n",
    "        if len(song_ids) > 0:\n",
    "            song_ids_all.append(song_ids)\n",
    "            album_ids_all.append(album_ids)\n",
    "            artist_ids_all.append(artist_ids)\n",
    "\n",
    "        medians = []\n",
    "\n",
    "        for k in range(0, len(song_ids_all)):\n",
    "            song_popularities = get_popularities(song_ids_all[k], headers, 'tracks', 50)\n",
    "            \n",
    "            more_features = get_more_features(song_ids_all[k], headers, 'audio-features', 50)\n",
    "\n",
    "            scaled_features, ids = preprocess_the_data(more_features)\n",
    "\n",
    "            track_message = get_mean_song(scaled_features, ids, headers)\n",
    "\n",
    "            artist_popularities = get_artist_popularities(artist_ids_all[k], headers)\n",
    "\n",
    "            artist_followers = get_artist_follower_count(artist_ids_all[k], headers, 50)\n",
    "\n",
    "            album_popularities = get_popularities(album_ids_all[k], headers, 'albums', 20)\n",
    "\n",
    "            all_raw_metrics = []\n",
    "            for j in range(0, len(song_popularities)):\n",
    "                jth_song_metric = sum(\n",
    "                    [(100 - song_popularities[j]),  # get the \n",
    "                    (100 - np.mean(artist_popularities[j])),\n",
    "                    (100 - np.mean(album_popularities[j])),\n",
    "                    ((80 - (np.mean(artist_followers[j]) / 1000000)) * 1.25)]\n",
    "                ) / 4\n",
    "                # append all metric scores to a list for each playlist\n",
    "                all_raw_metrics.append(jth_song_metric)\n",
    "            \n",
    "            medians.append(np.median(all_raw_metrics)) # get the median score for a given playlist\n",
    "\n",
    "        playlist_name = get_playlist_name(playlist_id_list[i], headers)\n",
    "        if type(playlist_name) != str:\n",
    "            print(f'\\nYour playlist score could not be calculated. Be sure the playlist is public before trying again.')\n",
    "        else:\n",
    "            print(f'For the playlist {playlist_name}, this is your indieness score:\\n{np.mean(medians)}\\nIt is scaled from 0-100, with 100 being the most indie and 0 being the least indie.')\n",
    "            print(f'\\n{track_message}')\n",
    "\n",
    "    return np.mean(medians)\n",
    "\n",
    "main('2wIJNW0Zn7LK6mi2slwdAF', config.id_, config.secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the cell above shows the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
